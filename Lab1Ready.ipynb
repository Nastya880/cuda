{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxHSi/KXimR1kp+TIfIjkS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nastya880/cuda/blob/main/Lab1Ready.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Лабораторная работа №1**\n",
        "\n",
        "**Основы работы с технологией CUDA. Гибридное программирование. Работа с глобальной памятью**"
      ],
      "metadata": {
        "id": "xZx1SsLhmfNo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Контрольные вопросы**\n",
        "\n",
        "1. Что такое гибридное программирование?\n",
        "\n",
        "```\n",
        "Гибридное программирование - это написание программы для гетерогенной\n",
        "аппаратной вычислительной структуры, например, для системы, состоящей\n",
        "из центрального процессора CPU и графического ускорителя GPU.\n",
        "```\n",
        "2. Что такое CUDA?\n",
        "\n",
        "```\n",
        "CUDA (Compute Unified Device Architecture) – \n",
        "- технология (библиотеки и расширенный Cи), предназначенная для разработки\n",
        "приложений для массивно-параллельных вычислительных устройств, заметно облегчает\n",
        "написание GPGPU (General Purposed Graphical Processing Unit)-приложений;\n",
        "- программно-аппаратная архитектура.\n",
        "```\n",
        "3. Основные положения программной модели CUDA?\n",
        "\n",
        "```\n",
        "GPU (Graphical Processing Unit, device) – это вычислительное устройство,\n",
        "которое:\n",
        "-    состоит из массива потоковых мультипроцессоров (streaming \n",
        "     multiprocessor, SM);\n",
        "-    является сопроцессором к центральному процессору CPU (host);\n",
        "-    имеет собственную память (DRAM);\n",
        "-    выполняет одновременно большое количество нитей.\n",
        "```\n",
        "\n",
        "4. Из чего состоит программный стек CUDA?\n",
        "\n",
        "```\n",
        "CPU (Application -> CUDA Libraries, CUDA RunTime, CUDA Drver) -> GPU\n",
        "```\n",
        "\n",
        "5. Что такое ядро в CUDA?\n",
        "\n",
        "```\n",
        "Ядро (kernel) – это функция, которая работает на GPU и которая \n",
        "может быть вызвана только с CPU. Ядро выполняется на сетке из блоков.\n",
        "```\n",
        "\n",
        "6. Какие расширения языка Си вводятся в CUDA?\n",
        "\n",
        "```\n",
        "Вводимые в CUDA расширения языка Си состоят из: \n",
        "-    спецификаторов функций, показывающих, где будет выполняться функция и откуда она может быть вызвана;  \n",
        "-    спецификаторов переменных, задающих тип памяти, используемый для данных переменных;\n",
        "-     директивы для запуска ядра из кода;\n",
        "-    встроенные переменные, содержащие информацию о текущей нити;\n",
        "-    дополнительные типы данных.\n",
        "```\n",
        "\n",
        "7. Какие встроенные переменные поддерживаются в CUDA и для чего они нужны?\n",
        "\n",
        "```\n",
        "В CUDA поддерживаются следующие встроенные переменные,\n",
        "содержащие информацию о текущей нити (рисунок 3):\n",
        "-    dim3  gridDim;  // размер сетки\n",
        "-    uint3 blockIdx; // индекс текущего блока в сетке\n",
        "-    dim3  blockDim; // размер блока \n",
        "-    uint3 threadIdx; // индекс текущей нити в блоке\n",
        "-    int   warpSize; // размер warp’а\n",
        "Встроенные переменные доступны в функции ядра.\n",
        "```\n",
        "\n",
        "8. Какие ограничения вводятся на функции, выполняемые на GPU?\n",
        "\n",
        "```\n",
        "- нельзя брать адрес функции (за исключением __global__);\n",
        "-    не поддерживается рекурсия;\n",
        "-    не поддерживаются static-переменные внутри функции;\n",
        "-    не поддерживается переменное число входных аргументов.\n",
        "```\n",
        "9. ДОП Какие ограничения вводятся на спецификаторы переменных, выполняемые на GPU?\n",
        "\n",
        "```\n",
        "-    нельзя применять к полям структуры (struct или union);\n",
        "-    не могут быть extern;\n",
        "-    запись в __constant__  может выполнять только CPU через специальные функции;\n",
        "-    __shared__ - переменные не могут инициализироваться при объявлении.\n",
        "```"
      ],
      "metadata": {
        "id": "izmIckjxoTdg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Настройка для запуска CUDA"
      ],
      "metadata": {
        "id": "sE_wPmSCmhew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global url.\"https://github.com/\".insteadOf git://github.com/\n",
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5dcXEezmh0B",
        "outputId": "0d6bed6b-e18d-47ef-ee91-36d7d9d1f7ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-qtej1alk\n",
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-qtej1alk\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4304 sha256=395eb04885eff6128cbc2f1c4435bc8cbc11f23432619800a1020a0bbfa435a3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-8kke5f0_/wheels/69/4f/dd/2613eddd1a84d8809a21caa3a45ccaae9eac9279231c2feabc\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n",
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo ln -s /usr/bin/gcc-5 /usr/local/cuda/bin/gcc\n",
        "!sudo ln -s /usr/bin/g++-5 /usr/local/cuda/bin/g++"
      ],
      "metadata": {
        "id": "qyAz7O_cmp2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!/usr/local/cuda/bin/nvcc --version"
      ],
      "metadata": {
        "id": "vJarM1zDnw1o",
        "outputId": "90d5cac0-f5db-4198-da84-328909a983aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2021 NVIDIA Corporation\n",
            "Built on Sun_Feb_14_21:12:58_PST_2021\n",
            "Cuda compilation tools, release 11.2, V11.2.152\n",
            "Build cuda_11.2.r11.2/compiler.29618528_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CUDA НАСТРОЕНА!"
      ],
      "metadata": {
        "id": "89paRzaVnrNz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание 1. В MS Visual Studio создать проект CUDA VS Wizard. Ознакомиться и запустить программу «Hello world». Получить информацию об устройстве. Измерить время выполнения программы. Результаты занести в отчёт. Запустить программу «Hello world» на всех мультипроцессорах в GPU. Измерить время выполнения программы. Результаты занести в отчёт.**"
      ],
      "metadata": {
        "id": "E4EMRv1pppEv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 часть. Запуск программы \"Hello world\""
      ],
      "metadata": {
        "id": "wtVOhTD9tE53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile hello.cu\n",
        "//функция hello, исполняемая на GPU\n",
        "//kernelName<<Dg, Db, Ns, S>>(args)\n",
        "//Dg - переменная dim3, размер сетки в блоках\n",
        "//Db - переменная dim3, размер блока в нитях\n",
        "//Ns - переменная size_t, объем разделяемой памяти в байтах для каждого блока\n",
        "//S - поток для вызова\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void hello_kernel(void)\n",
        "{\n",
        "  printf(\"Hello, world from the device!\\n\");\n",
        "}\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "  printf(\"Hello, world from the host!\\n\");\n",
        "\n",
        "  hello_kernel<<<1,1>>>();\n",
        "\n",
        "  cudaDeviceSynchronize();\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4IhcsHumuTC",
        "outputId": "ec709ddb-60b9-4a0c-b4d7-d6069a363d2d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting hello.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc hello.cu -o hello -Wno-deprecated-gpu-targets\n",
        "!nvprof ./hello"
      ],
      "metadata": {
        "id": "_KbNN0QKp_O-",
        "outputId": "4e1d2b26-60ec-44e9-b72a-062aa771c2a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, world from the host!\n",
            "==375== NVPROF is profiling process 375, command: ./hello\n",
            "Hello, world from the device!\n",
            "==375== Profiling application: ./hello\n",
            "==375== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  89.054us         1  89.054us  89.054us  89.054us  hello_kernel(void)\n",
            "      API calls:   99.81%  346.99ms         1  346.99ms  346.99ms  346.99ms  cudaLaunchKernel\n",
            "                    0.11%  371.18us         1  371.18us  371.18us  371.18us  cuDeviceTotalMem\n",
            "                    0.04%  147.83us       101  1.4630us     134ns  62.720us  cuDeviceGetAttribute\n",
            "                    0.03%  108.65us         1  108.65us  108.65us  108.65us  cudaDeviceSynchronize\n",
            "                    0.01%  33.971us         1  33.971us  33.971us  33.971us  cuDeviceGetName\n",
            "                    0.00%  5.4320us         1  5.4320us  5.4320us  5.4320us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.5250us         3     508ns     204ns     961ns  cuDeviceGetCount\n",
            "                    0.00%  1.2820us         2     641ns     296ns     986ns  cuDeviceGet\n",
            "                    0.00%     270ns         1     270ns     270ns     270ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 часть. Информация об устройстве"
      ],
      "metadata": {
        "id": "P5TeqkrCs7fT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Информация о возможностях GPU возвращается в виде структуры cudaDeviceProp\n",
        "struct cudaDeviceProp\n",
        "{\n",
        "    char name[256];           //название устройства\n",
        "    size_t totalGlobalMem;    //полный объем глобальной памяти в байтах\n",
        "    size_t sharedMemPerBlock; //объем разделяемой памяти в блоке в байтах\n",
        "    int regsPerBlock;         //кол-во 32битовых регистров в блоке\n",
        "    int warpSize;             //размер warp\n",
        "    size_t memPitch;          //макс pitch в байтах, допустимый функциями копирования\n",
        "                              //памяти, выделенной через cudaMallocPitch\n",
        "\n",
        "    int maxThreadsPerBlock;   //макс кол-во активных нитей в блоке\n",
        "    int maxThreadsDim[3];     //макс размер блока\n",
        "    int maxGridSize[3];       //макс размер сетки\n",
        "    size_t totalConstMem;     //объем константной памяти\n",
        "    int major;                //compute capability, старший номер\n",
        "    int minor;                 //compute capability, младший номер\n",
        "    int clockRate;            //частота в килогерцах\n",
        "    size_t textureAlignment;  //выравнивание памяти для текстур\n",
        "    int deviceOverlap;        //можно ли осуществлять копирование параллельно с вычислениями\n",
        "\n",
        "    int multiProcessorCount;  //количетсво мультипроцессоров в GPU\n",
        "    int kernelExecTimeOutEnables; //1, если есть ограничение на время выполнения ядра\n",
        "\n",
        "    int integrated;           //1, если GPU встроено в материнскую плату\n",
        "    int canMapHostMemory;     //1, если можно отбражать памяти CPU в куда для использования cudaHostAlloc, cudaHostGetDevicePointer\n",
        "\n",
        "    int computeMode;          //режим, в котором находится GPU\n",
        "                              // cudeComputeModeDefault\n",
        "                              // cudaComputeModeExclusive - только одна нить, может вызвать cudaSetDevice для данного GPU\n",
        "                              // cudaComputeModeProhibited - ни одна нить не может вызвать cudaSetDevice для данного GPU\n",
        "}"
      ],
      "metadata": {
        "id": "PhRIAzaNtmYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile deviceInfo.cu\n",
        "#include <cstdio>\n",
        "#include <cuda_runtime.h>\n",
        "#include <chrono>\n",
        "\n",
        "int main (int argc, char * argv [] )\n",
        "{\n",
        "    int deviceCount;\n",
        "    cudaDeviceProp devProp{};\n",
        "    cudaGetDeviceCount ( &deviceCount );\n",
        "    printf ( \"Found %d devices\\n\", deviceCount );\n",
        "    for ( int device = 0; device < deviceCount; device++)\n",
        "    {cudaGetDeviceProperties ( &devProp, device );\n",
        "        printf (\"Device %d\\n\", device );\n",
        "        printf (\"Compute capability : %d.%d\\n\", devProp.major, devProp.minor);\n",
        "        printf (\"Name : %s\\n\", devProp.name);\n",
        "        // Полный объем глобальной памяти в Mбайтах:\n",
        "        printf (\"Total Global Mem: %lu\\n\", (devProp.totalGlobalMem/(1024*1024)));\n",
        "        printf (\"Shared memory per block: %zu\\n\" , devProp.sharedMemPerBlock );\n",
        "        printf (\"Registers per block : %d\\n\", devProp.regsPerBlock);\n",
        "        printf (\"Warp size : %d\\n\", devProp.warpSize);\n",
        "        printf (\"Max threads per block: %d\\n\", devProp.maxThreadsPerBlock);\n",
        "        printf (\"Total constant memory: %zu\\n\", devProp.totalConstMem);\n",
        "        printf (\"Clock Rate : %d\\n\", devProp.clockRate);\n",
        "        printf (\"Texture Alignment : %zu\\n\", devProp.textureAlignment);\n",
        "        printf (\"Device Overlap : %d\\n\", devProp.deviceOverlap);\n",
        "        printf (\"Multiprocessor Count: %d\\n\", devProp.multiProcessorCount);\n",
        "        printf (\"Max Threads Dim : %d %d %d\\n\", devProp.maxThreadsDim[0],\n",
        "                devProp.maxThreadsDim[1], devProp.maxThreadsDim[2] );\n",
        "        printf (\"Max Grid Size : %d %d %d\\n\", devProp.maxGridSize [0],\n",
        "                devProp.maxGridSize [1], devProp.maxGridSize [2]);\n",
        "    }\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "rpLrrIFjruAf",
        "outputId": "89b4369e-d3e8-493f-e6c5-fb24426faa9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing deviceInfo.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc deviceInfo.cu -o deviceInfo -Wno-deprecated-gpu-targets\n",
        "!nvprof ./deviceInfo"
      ],
      "metadata": {
        "id": "9QsXoeStsERu",
        "outputId": "00fcec3e-3de5-4f6e-a232-357f9ddec6a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==2089== NVPROF is profiling process 2089, command: ./deviceInfo\n",
            "Found 1 devices\n",
            "Device 0\n",
            "Compute capability : 7.5\n",
            "Name : Tesla T4\n",
            "Total Global Mem: 15109\n",
            "Shared memory per block: 49152\n",
            "Registers per block : 65536\n",
            "Warp size : 32\n",
            "Max threads per block: 1024\n",
            "Total constant memory: 65536\n",
            "Clock Rate : 1590000\n",
            "Texture Alignment : 512\n",
            "Device Overlap : 1\n",
            "Multiprocessor Count: 40\n",
            "Max Threads Dim : 1024 1024 64\n",
            "Max Grid Size : 2147483647 65535 65535\n",
            "==2089== Profiling application: ./deviceInfo\n",
            "==2089== Profiling result:\n",
            "No kernels were profiled.\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            "      API calls:   53.66%  378.44us         1  378.44us  378.44us  378.44us  cuDeviceTotalMem\n",
            "                   21.11%  148.90us       101  1.4740us     129ns  63.768us  cuDeviceGetAttribute\n",
            "                   18.50%  130.46us         1  130.46us  130.46us  130.46us  cudaGetDeviceProperties\n",
            "                    5.42%  38.207us         1  38.207us  38.207us  38.207us  cuDeviceGetName\n",
            "                    0.79%  5.5580us         1  5.5580us  5.5580us  5.5580us  cuDeviceGetPCIBusId\n",
            "                    0.20%  1.3890us         3     463ns     191ns     917ns  cuDeviceGetCount\n",
            "                    0.15%  1.0530us         2     526ns     189ns     864ns  cuDeviceGet\n",
            "                    0.13%     916ns         1     916ns     916ns     916ns  cudaGetDeviceCount\n",
            "                    0.05%     318ns         1     318ns     318ns     318ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile helloTime.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <chrono>\n",
        "\n",
        "__global__ void hello_kernel(void)\n",
        "{\n",
        "  printf(\"Hello, world from the device!\\n\");\n",
        "}\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "  /*unsigned int timer;\n",
        "  cutCreateTimer(&timer);\n",
        "  curStartTimer(timer);*/\n",
        "\n",
        "  printf(\"Hello, world from the host!\\n\");\n",
        "\n",
        "  // инициализируем события\n",
        "  cudaEvent_t start, stop;\n",
        "  float elapsedTime;\n",
        "\n",
        "  // создаем события\n",
        "  cudaEventCreate(&start);\n",
        "  cudaEventCreate(&stop);\n",
        "  // запись события\n",
        "  cudaEventRecord(start, 0);\n",
        "  cudaEventRecord(stop,0);\n",
        "\n",
        "  hello_kernel<<<1,1>>>(); \n",
        " \n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&elapsedTime, start, stop);\n",
        "\n",
        "  // вывод информации \n",
        "  printf(\"Time spent executing by the GPU: %.7f  millseconds\\n\", elapsedTime);\n",
        "\n",
        "  // уничтожение события \n",
        "  cudaEventDestroy(start);\n",
        "  cudaEventDestroy(stop);\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "rQOp-rlpwGb3",
        "outputId": "854195d8-b3a4-4acb-9d2d-3e679451489e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing helloTime.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc helloTime.cu -o helloTime -Wno-deprecated-gpu-targets\n",
        "!nvprof ./helloTime"
      ],
      "metadata": {
        "id": "r1vct3XxwtKO",
        "outputId": "94dce7ea-32c2-49bc-8c6c-e5152cb243a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, world from the host!\n",
            "==2140== NVPROF is profiling process 2140, command: ./helloTime\n",
            "Time spent executing by the GPU: 0.0038080  millseconds\n",
            "==2140== Profiling application: ./helloTime\n",
            "==2140== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  88.926us         1  88.926us  88.926us  88.926us  hello_kernel(void)\n",
            "      API calls:   99.79%  305.22ms         2  152.61ms  1.0210us  305.22ms  cudaEventCreate\n",
            "                    0.11%  350.44us         1  350.44us  350.44us  350.44us  cuDeviceTotalMem\n",
            "                    0.05%  143.55us       101  1.4210us     129ns  63.151us  cuDeviceGetAttribute\n",
            "                    0.02%  74.335us         1  74.335us  74.335us  74.335us  cudaLaunchKernel\n",
            "                    0.01%  33.183us         1  33.183us  33.183us  33.183us  cuDeviceGetName\n",
            "                    0.00%  12.900us         2  6.4500us  1.9520us  10.948us  cudaEventRecord\n",
            "                    0.00%  8.8070us         1  8.8070us  8.8070us  8.8070us  cudaEventSynchronize\n",
            "                    0.00%  5.5180us         1  5.5180us  5.5180us  5.5180us  cuDeviceGetPCIBusId\n",
            "                    0.00%  3.2850us         1  3.2850us  3.2850us  3.2850us  cudaEventElapsedTime\n",
            "                    0.00%  2.6230us         2  1.3110us     870ns  1.7530us  cudaEventDestroy\n",
            "                    0.00%  1.4520us         3     484ns     180ns     893ns  cuDeviceGetCount\n",
            "                    0.00%  1.2660us         2     633ns     250ns  1.0160us  cuDeviceGet\n",
            "                    0.00%     269ns         1     269ns     269ns     269ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание 2. Написать программу на Cи с использованием CUDA runtime API в соответствии с вариантом задания. Измерить время работы программы для различных значений параметров. Результаты занести в отчёт. Написать программу для верификации результатов.**\n",
        "\n",
        "**Даны матрицы А и В из NxN натуральных (ненулевых) элементов (задаются случайно). Матрицы расположены в глобальной памяти.\n",
        "Написать программу, выполняющую перемножение двух матриц на GPU.** "
      ],
      "metadata": {
        "id": "YZ2fVIAXvjbA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Нужно прочесть 2N значений из глобальной памяти, выполнить 2N арифметических операций \n",
        "0. инициализация CUDA\n",
        "1. выделение видеопамяти для хранения данных программы\n",
        "2. копирование необходимых для работы функции данных из оперативной памяти в видеопамять\n",
        "3. вызов функции CUDA\n",
        "4. копирование возвращаемых данных из видеопамяти в оперативную\n",
        "5. освобождение видеопамяти"
      ],
      "metadata": {
        "id": "qAkO5SFD9j6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrixMult.cu\n",
        "#include \"cuda_runtime.h\"\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "#define BLOCK_SIZE 16\n",
        "\n",
        "__global__ void matrixMult(int *A, int *B, int *C, int N) \n",
        "{\n",
        "    int i0 = N * (blockDim.y * blockIdx.y +  threadIdx.y);\n",
        "    int j0 = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "    int sum = 0;\n",
        "\n",
        "    for (int k = 0; k < N; k++)\n",
        "    sum += A[i0 + k] * B[k * N + j0]; //смещение для записываемого элемента\n",
        "\n",
        "    int ind = N * (blockDim.y * blockIdx.y + threadIdx.y) + blockDim.x * blockIdx.x + threadIdx.x;\n",
        "    C[ind] = sum;\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    // количество строк и столбцов матрицы\n",
        "    int N = 100;\n",
        "    \n",
        "    size_t ABCsize = N * N * sizeof(int);\n",
        "    \n",
        "    int *h_A = (int *)malloc(ABCsize);\n",
        "    int *h_B = (int *)malloc(ABCsize);\n",
        "    int *h_C = (int *)malloc(ABCsize);\n",
        " \n",
        "    //заполнение матриц\n",
        "    for (int i = 0; i < N * N; ++i)\n",
        "    {\n",
        "        h_A[i] = rand() % (int)RAND_MAX;\n",
        "    }\n",
        "\n",
        "    for (int i = 0; i < N * N; ++i)\n",
        "    {\n",
        "        h_B[i] = rand()%(int)RAND_MAX;\n",
        "    }\n",
        "    \n",
        "    int *d_A = NULL;\n",
        "    cudaMalloc((void **)&d_A, Asize);\n",
        "    \n",
        "    int *d_B = NULL;\n",
        "    cudaMalloc((void **)&d_B, Bsize);\n",
        "    \n",
        "    int * d_C = NULL;\n",
        "    cudaMalloc((void **)&d_C, Csize);\n",
        "    cudaMemcpy(d_A, h_A, ABCsize, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, ABCsize, cudaMemcpyHostToDevice);\n",
        " \n",
        "    dim3 threadsPerBlock = dim3(BLOCK_SIZE, BLOCK_SIZE);\n",
        "    dim3 blocksPerGrid = dim3(N / BLOCK_SIZE, N /  BLOCK_SIZE);\n",
        "    cudaEventRecord(start, 0);\n",
        "    \n",
        "    matrixMult<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C, N);\n",
        "    \n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    float KernelTime;\n",
        "    cudaEventElapsedTime(&KernelTime, start, stop);\n",
        "    printf(\"KernelTime: %.2f milliseconds\\n\", KernelTime);\n",
        "    \n",
        "    cudaMemcpy(h_C, d_C, Csize, cudaMemcpyDeviceToHost);\n",
        "    \n",
        "    printf(\"MULTIPLICATE\\n\");\n",
        "    for (int i = 0; i < N; i++)\n",
        "    {\n",
        "        for (int j = 0; j < N; j++)\n",
        "        {\n",
        "            int sum = 0;\n",
        "                for (int k = 0; k < N; k++) \n",
        "                    sum += h_A[i * N + k] * h_B[k * N + j];\n",
        "        }\n",
        "    }\n",
        "    printf(\"END\\n\");\n",
        "    \n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(h_C);\n",
        "\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "W8ms3YPexoCP",
        "outputId": "f476befd-38c1-4491-ba76-f6d7c730c290",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting matrixMult.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc matMult.cu -o matMult -Wno-deprecated-gpu-targets\n",
        "!nvprof ./matMult"
      ],
      "metadata": {
        "id": "w0j4VaPaxz25",
        "outputId": "44ab1771-d3bf-4665-a5ad-e1dd75661269",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==2392== NVPROF is profiling process 2392, command: ./matMult\n",
            "Arows = 112\n",
            "KernelTime: 0.04 milliseconds\n",
            "Test STARTED\n",
            "Test PASSED\n",
            "==2392== Profiling application: ./matMult\n",
            "==2392== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   51.19%  21.375us         1  21.375us  21.375us  21.375us  matrixMult(int*, int*, int*, int)\n",
            "                   34.87%  14.560us         2  7.2800us  6.4320us  8.1280us  [CUDA memcpy HtoD]\n",
            "                   13.95%  5.8240us         1  5.8240us  5.8240us  5.8240us  [CUDA memcpy DtoH]\n",
            "      API calls:   99.63%  300.91ms         2  150.46ms     955ns  300.91ms  cudaEventCreate\n",
            "                    0.12%  373.97us         1  373.97us  373.97us  373.97us  cuDeviceTotalMem\n",
            "                    0.07%  219.43us         3  73.142us  2.5110us  213.14us  cudaMalloc\n",
            "                    0.05%  149.40us       101  1.4790us     127ns  64.348us  cuDeviceGetAttribute\n",
            "                    0.05%  138.39us         3  46.131us  4.1170us  120.50us  cudaFree\n",
            "                    0.04%  113.16us         3  37.721us  29.275us  44.476us  cudaMemcpy\n",
            "                    0.01%  39.609us         1  39.609us  39.609us  39.609us  cuDeviceGetName\n",
            "                    0.01%  25.895us         1  25.895us  25.895us  25.895us  cudaLaunchKernel\n",
            "                    0.01%  23.567us         1  23.567us  23.567us  23.567us  cudaEventSynchronize\n",
            "                    0.00%  7.5820us         2  3.7910us  3.2660us  4.3160us  cudaEventRecord\n",
            "                    0.00%  6.1350us         1  6.1350us  6.1350us  6.1350us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.2790us         1  2.2790us  2.2790us  2.2790us  cudaEventElapsedTime\n",
            "                    0.00%  2.1690us         2  1.0840us     450ns  1.7190us  cudaEventDestroy\n",
            "                    0.00%  1.9940us         3     664ns     210ns  1.5140us  cuDeviceGetCount\n",
            "                    0.00%  1.7380us         2     869ns     376ns  1.3620us  cuDeviceGet\n",
            "                    0.00%     246ns         1     246ns     246ns     246ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "o4E24WqDvyRV"
      }
    }
  ]
}